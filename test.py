import gradio as gr
import subprocess
import os
import yaml
from tempfile import NamedTemporaryFile

# æ¨¡å‹å’Œæ”»å‡»ç®—æ³•è„šæœ¬ç›®å½•
MODEL_SCRIPT_DIR = ""
ATTACK_SCRIPT_DIR = ""
ATTACK_SCRIPT_PATH = ""

import os, time, json, glob

MAX_JSON_BYTES = 0.5 * 1024 * 1024          # â‰¤512KB æ‰åœ¨ gr.JSON ä¸­å®Œæ•´å±•ç¤º
PREVIEW_HEAD_BYTES = 12_000              # å¤§æ–‡ä»¶åªè¯»å‰ 12KB ä½œä¸ºé¢„è§ˆ
def _fmt_size(n): return f"{n/1024/1024:.2f} MB"

def build_json_preview_from_file(path, head_bytes=PREVIEW_HEAD_BYTES):
    try:
        size = os.path.getsize(path)
        with open(path, "r", encoding="utf-8", errors="replace") as f:
            head = f.read(head_bytes)
        if size > head_bytes:
            head += "\n...\n/* truncated preview: file is " + _fmt_size(size) + " */"
        return head, size
    except Exception as e:
        return f"æ— æ³•è¯»å–ç»“æœæ–‡ä»¶ç”¨äºé¢„è§ˆï¼š{e}", -1


# å„è¯„æµ‹çš„ç»“æœè·¯å¾„æ¨¡æ¿ï¼ˆå¯æŒ‰éœ€ç»§ç»­æ‰©å±• attackã€robustness ç­‰ï¼‰
# æ”¯æŒç²¾ç¡®æ–‡ä»¶ & é€šé…ç¬¦ã€‚å˜é‡ï¼š{output_dir},{model_name},{dataset}
RESULT_PATTERNS = {

}

PREFERRED_JSON_BASENAMES = {
    "results.json", "result.json", "metrics.json", "eval.json", "evaluation.json", "summary.json"
}


def _expand_patterns(eval_kind, **vars_dict):
    patterns = RESULT_PATTERNS.get(eval_kind, [])
    expanded = []
    for pat in patterns:
        pat_fmt = pat.format(**{k: str(v).strip().rstrip("/") for k, v in vars_dict.items()})
        if any(ch in pat_fmt for ch in "*?[]"):
            expanded.extend(glob.glob(pat_fmt))
        else:
            expanded.append(pat_fmt)
    # å»é‡ä¿åº
    seen, uniq = set(), []
    for p in expanded:
        if p not in seen:
            uniq.append(p); seen.add(p)
    return uniq

def _pick_newest_json(candidates, start_ts, relax_time=False):
    scored = []
    for path in candidates:
        try:
            st = os.stat(path)
            if relax_time or st.st_mtime >= start_ts - 1:
                name = os.path.basename(path).lower()
                score = 3 if name in PREFERRED_JSON_BASENAMES else 1
                scored.append((score, st.st_mtime, path))
        except FileNotFoundError:
            continue
    if not scored:
        return None
    scored.sort(key=lambda x: (x[0], x[1]), reverse=True)
    return scored[0][2]

def locate_result_json(eval_kind, output_dir, model_name, dataset, start_ts, **extra):
    """
    ä»…æŒ‰ RESULT_PATTERNS å±•å¼€çš„å€™é€‰è¿›è¡ŒåŒ¹é…ï¼š
      1) å…ˆä½¿ç”¨ä¸¥æ ¼æ—¶é—´è¿‡æ»¤ï¼ˆmtime >= start_ts-1ï¼‰
      2) è‹¥æ²¡æœ‰å‘½ä¸­ï¼Œå†æ”¾å®½æ—¶é—´è¿‡æ»¤
    ä¸åšä»»ä½•ç›®å½•å…œåº•æ‰«æã€‚
    å…¼å®¹ {interference} / {interference_type} ä¸¤ç§å†™æ³•ã€‚
    """
    dataset_str = str(dataset).strip()
    vars_dict = dict(
        output_dir=str(output_dir).rstrip("/"),
        model_name=str(model_name).strip(),
        dataset=dataset_str,
        dataset_lower=dataset_str.lower(),
        dataset_slug=dataset_str.replace(" ", "_").lower(),
        **extra
    )

    # 1) æ¨¡æ¿å±•å¼€ â†’ ä¸¥æ ¼æ—¶é—´ç­›é€‰
    expanded = _expand_patterns(eval_kind, **vars_dict)  # åªç”¨æ¨¡æ¿ï¼
    path = _pick_newest_json(expanded, start_ts, relax_time=False)
    if path:
        return path

    # 2) æ”¾å®½æ—¶é—´ï¼ˆä»åªåœ¨æ¨¡æ¿å±•å¼€çš„å€™é€‰é‡ŒæŒ‘ï¼‰
    path = _pick_newest_json(expanded, start_ts, relax_time=True)
    return path  # å¯èƒ½ä¸º Noneï¼›ç”±ä¸Šå±‚å†³å®šå¦‚ä½•æç¤º



# å·¥å…·ï¼šåˆ—å‡ºè„šæœ¬æ–‡ä»¶
def list_sh_scripts(directory):
    return [f for f in os.listdir(directory) if f.endswith(".sh")]


# é€šç”¨è„šæœ¬åŠ è½½é€»è¾‘ï¼ˆå¯å¸¦ portï¼‰
def launch_script(script_dir, script_name, gpu, port=None):
    if not script_name:
        yield "âš ï¸ æœªé€‰æ‹©è„šæœ¬"
        return

    script_path = os.path.join(script_dir, script_name)
    if not os.path.exists(script_path):
        yield f"âŒ æ‰¾ä¸åˆ°è„šæœ¬æ–‡ä»¶: {script_path}"
        return

    command = f"CUDA_VISIBLE_DEVICES={gpu} bash {script_path}"
    if port:
        command += f" {gpu} {port}"
    else:
        command += f" {gpu}"

    try:
        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
        output_lines = []
        for line in iter(process.stdout.readline, ''):
            output_lines.append(line.strip())
            yield "\n".join(output_lines)

        process.wait()
        if process.returncode == 0:
            yield "âœ… åŠ è½½å®Œæˆ"
        else:
            yield "âŒ å¯åŠ¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥è„šæœ¬"

    except Exception as e:
        yield f"âŒ å¯åŠ¨å¤±è´¥: {str(e)}"


# æ¨¡å‹å…³é—­ï¼ˆæŒ‰ç«¯å£ï¼‰
def stop_model(port):
    try:
        command = f"fuser -k {port}/tcp"
        subprocess.run(command, shell=True, check=True)
        return f"ğŸ›‘ å·²å…³é—­ç«¯å£ {port} ä¸Šçš„æœåŠ¡"
    except subprocess.CalledProcessError:
        return f"âš ï¸ æœªæ‰¾åˆ°æœåŠ¡æˆ–å…³é—­å¤±è´¥"


# æ”»å‡»ç®—æ³•å…³é—­ï¼ˆæŒ‰ ç«¯å£ï¼‰
def stop_attack(port=1337):
    try:
        command = f"fuser -k {port}/tcp"
        subprocess.run(command, shell=True, check=True)
        return f"ğŸ›‘ å·²å…³é—­ç«¯å£ {port} ä¸Šçš„æ”»å‡»ç®—æ³•è¿›ç¨‹"
    except subprocess.CalledProcessError:
        return f"âš ï¸ æœªæ‰¾åˆ°ç›¸å…³è¿›ç¨‹æˆ–å…³é—­å¤±è´¥"

# ===== å›ºå®šæ˜ å°„ï¼šæ¨¡å‹åç§° â†’ è„šæœ¬æ–‡ä»¶å =====
MODEL_SCRIPTS_MAP = {

}

# ===== å›ºå®šæ˜ å°„ï¼šæ”»å‡»ç®—æ³•åç§° â†’ è„šæœ¬æ–‡ä»¶å =====
ATTACK_SCRIPTS_MAP = {
}


# ===== å…¨å±€ï¼šä»»åŠ¡/æ•°æ®é›† â†’ åˆæ³• infer/eval æ­é…ï¼ˆé€šç”¨äºæ‰€æœ‰è¯„æµ‹ï¼‰=====
CONFIG_MATRIX = {
    }

# â€”â€” è”åŠ¨ï¼šå¼•ç”¨ CONFIG_MATRIX â€”â€”
def _on_task_change(task):
    if not task:
        return (gr.update(choices=[], value=None),
                gr.update(choices=[], value=None),
                gr.update(value=""), gr.update(value=""),
                gr.update(value=False))
    dsets = list(CONFIG_MATRIX[task].keys())
    return (gr.update(choices=dsets, value=None),
            gr.update(choices=[], value=None),
            gr.update(value=""), gr.update(value=""),
            gr.update(value=False))


def _on_dataset_change(task, dataset):
    if not (task and dataset):
        return gr.update(choices=[], value=None), gr.update(value=""), gr.update(value="")
    opts = CONFIG_MATRIX[task][dataset]
    scheme_choices = [o.get("label") or f"{o['infer']} / {o['eval']}" for o in opts]
    infer, eval_ = opts[0]["infer"], opts[0]["eval"]
    return gr.update(choices=scheme_choices, value=scheme_choices[0]), gr.update(value=infer), gr.update(
        value=eval_)


def _on_scheme_change(task, dataset, scheme_label):
    if not (task and dataset and scheme_label):
        return gr.update(), gr.update()
    for o in CONFIG_MATRIX[task][dataset]:
        lbl = o.get("label") or f"{o['infer']} / {o['eval']}"
        if lbl == scheme_label:
            return gr.update(value=o["infer"]), gr.update(value=o["eval"])
    return gr.update(), gr.update()


def _toggle_custom(allow, task, dataset, scheme_label):
    locked = False
    if task and dataset and scheme_label:
        for o in CONFIG_MATRIX[task][dataset]:
            lbl = o.get("label") or f"{o['infer']} / {o['eval']}"
            if lbl == scheme_label:
                locked = o.get("locked", False)
                break
    can_edit = bool(allow and not locked)
    return gr.update(interactive=can_edit), gr.update(interactive=can_edit)


# --- shared validators (å…¨å±€å…±äº«) ---
def validate_combo(task, dataset, scheme_label, infer, eval_, allow_custom, config=CONFIG_MATRIX):
    if not (task and dataset):
        gr.Warning("è¯·é€‰æ‹©ä»»åŠ¡ä¸æ•°æ®é›†")
        return False
    if allow_custom:
        return True
    for o in config.get(task, {}).get(dataset, []):
        lbl = o.get("label") or f"{o['infer']} / {o['eval']}"
        if lbl == scheme_label and o["infer"] == infer and o["eval"] == eval_:
            return True
    gr.Error("æ‰€é€‰ç»„åˆä¸åœ¨æ”¯æŒçŸ©é˜µä¸­ï¼›è¯·æ›´æ¢â€œæ¨èæ­é…â€æˆ–å‹¾é€‰â€œå…è®¸è‡ªå®šä¹‰â€ã€‚")
    return False

def launch_script_by_map(script_dir, mapping, name, gpu, port=None):
    if not name:
        yield "âš ï¸ æœªé€‰æ‹©åç§°"
        return
    if name not in mapping:
        yield f"âŒ æœªæ‰¾åˆ°å¯¹åº”è„šæœ¬ï¼š{name}"
        return

    script_file = mapping[name]
    script_path = os.path.join(script_dir, script_file)
    if not os.path.exists(script_path):
        yield f"âŒ æ‰¾ä¸åˆ°è„šæœ¬æ–‡ä»¶: {script_path}"
        return

    command = f"CUDA_VISIBLE_DEVICES={gpu} bash {script_path} {gpu}"
    if port:
        command += f" {port}"

    try:
        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
        output_lines = []
        for line in iter(process.stdout.readline, ""):
            output_lines.append(line.strip())
            yield "\n".join(output_lines)

        process.wait()
        if process.returncode == 0:
            yield "âœ… åŠ è½½å®Œæˆ"
        else:
            yield "âŒ å¯åŠ¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥è„šæœ¬"
    except Exception as e:
        yield f"âŒ å¯åŠ¨å¤±è´¥: {str(e)}"


# ========== Gradio UI ==========
with gr.Blocks() as demo:
    gr.Markdown("# æ¨¡å‹æœåŠ¡ + æ”»å‡»ç®—æ³•åŠ è½½ + å¤šç»´åº¦è¯„æµ‹")

    # === æ¨¡å‹åŠ è½½ ===
    for i in range(1, 4):
        with gr.Accordion(label=f"æ¨¡å‹ {i} é…ç½®", open=(i == 1)):
            model_name = gr.Dropdown(label="é€‰æ‹©æ¨¡å‹", choices=list(MODEL_SCRIPTS_MAP.keys()), interactive=True)
            gpu = gr.Textbox(label="GPU ç¼–å·", value="0")
            port = gr.Textbox(label="ç«¯å£å·", value=str(3000 + i - 1))
            output = gr.Textbox(label="è¾“å‡ºä¿¡æ¯", lines=10)

            launch = gr.Button(f"å¯åŠ¨æ¨¡å‹ {i}")
            stop = gr.Button(f"å…³é—­æ¨¡å‹ {i}")


            def _launch_model(name, gpu, port):
                yield from launch_script_by_map(MODEL_SCRIPT_DIR, MODEL_SCRIPTS_MAP, name, gpu, port)

            launch.click(fn=_launch_model, inputs=[model_name, gpu, port], outputs=output)

            stop.click(fn=stop_model, inputs=port, outputs=output)

    # === æ”»å‡»ç®—æ³•åŠ è½½ ===
    gr.Markdown("## æ”»å‡»ç®—æ³•åŠ è½½")
    with gr.Accordion("æ”»å‡»ç®—æ³•éƒ¨ç½²", open=False):
        attack_name = gr.Dropdown(label="é€‰æ‹©æ”»å‡»ç®—æ³•", choices=list(ATTACK_SCRIPTS_MAP.keys()), interactive=True)
        # æ—è¾¹æ”¾ä¸€æ¡æç¤º
        attack_gpu = gr.Textbox(label="GPU ç¼–å·", value="0")
        attack_output = gr.Textbox(label="è¾“å‡ºä¿¡æ¯", lines=10)

        attack_launch = gr.Button("åŠ è½½æ”»å‡»ç®—æ³•")
        attack_stop = gr.Button("å…³é—­æ”»å‡»ç®—æ³•")


        def _launch_attack(name, gpu):
            yield from launch_script_by_map(ATTACK_SCRIPT_DIR, ATTACK_SCRIPTS_MAP, name, gpu)

        attack_launch.click(fn=_launch_attack, inputs=[attack_name, attack_gpu], outputs=attack_output)

        attack_stop.click(fn=stop_attack, outputs=attack_output)


    def build_support_matrix_md(config):
        lines = ["| ä»»åŠ¡ | æ•°æ®é›† | æ¨èæ­é…ï¼ˆinfer â†’ evalï¼‰ |", "|---|---|---|"]
        for task, dsets in config.items():
            for ds, opts in dsets.items():
                pairs = " / ".join([f"{o['infer']} â†’ {o['eval']}" for o in opts])
                lines.append(f"| {task} | {ds} | {pairs} |")
        return "\n".join(lines)


    with gr.Accordion("ğŸ“š æ”¯æŒçŸ©é˜µï¼ˆå…¨å±€ï¼Œé€‚ç”¨äºæ‰€æœ‰è¯„æµ‹ï¼‰", open=False):
        gr.Markdown(build_support_matrix_md(CONFIG_MATRIX))

    # === å‡†ç¡®æ€§è¯„æµ‹ ===
    gr.Markdown("## å‡†ç¡®æ€§è¯„æµ‹ä»»åŠ¡")

    with gr.Accordion("è¿è¡Œå‡†ç¡®æ€§è¯„æµ‹", open=False):
        # é€‰æ‹©å™¨ï¼ˆå¼•ç”¨å…¨å±€ CONFIG_MATRIXï¼‰
        with gr.Row():
            acc_task = gr.Dropdown(label="ä»»åŠ¡", choices=list(CONFIG_MATRIX.keys()), interactive=True)
            acc_dataset = gr.Dropdown(label="æ•°æ®é›†", choices=[], interactive=True)
            acc_scheme = gr.Dropdown(label="æ¨èæ­é…", choices=[], interactive=True)

        with gr.Row():
            acc_infer_type = gr.Textbox(label="æ¨ç†ç±»å‹", interactive=False)
            acc_eval_type = gr.Textbox(label="è¯„æµ‹ç±»å‹", interactive=False)
        acc_allow_custom = gr.Checkbox(label="å…è®¸è‡ªå®šä¹‰ infer/evalï¼ˆéç‰¹æ®Šä»»åŠ¡ï¼‰", value=False)

        with gr.Row():
            acc_model = gr.Textbox(label="æ¨¡å‹åç§°", value="qwen-vl")
            acc_port = gr.Textbox(label="æ¨¡å‹ç«¯å£", value="3000")

        with gr.Row():
            acc_output_dir = gr.Textbox(label="è¾“å‡ºç›®å½•",
                                        value="")
            acc_gpu = gr.Textbox(label="GPU ç¼–å·", value="0")

        # è¡¥å› keyï¼ˆä½ çš„ _acc_run é‡Œéœ€è¦ï¼‰
        acc_key = gr.Textbox(label="å¯†é’¥ keyï¼ˆå¯é€‰ï¼‰", value="")

        acc_button = gr.Button("è¿è¡Œå‡†ç¡®æ€§è¯„æµ‹", variant="primary")
        acc_output = gr.Textbox(label="è¾“å‡ºæ—¥å¿—", lines=20, show_copy_button=True)

        # æ–°å¢ä¸‰ä»¶å¥—ï¼šå°æ–‡ä»¶ JSONã€å¤§æ–‡ä»¶é¢„è§ˆã€ä¸‹è½½
        acc_result_json = gr.JSON(label="è¯„æµ‹ç»“æœï¼ˆâ‰¤512KB è‡ªåŠ¨å±•ç¤ºï¼‰", visible=False)
        acc_result_preview = gr.Code(label="ç»“æœé¢„è§ˆï¼ˆå¤§æ–‡ä»¶æˆªæ–­ï¼‰", language="json", visible=False)
        acc_result_file = gr.File(label="ä¸‹è½½å®Œæ•´ç»“æœ", visible=False)




        acc_task.change(_on_task_change, inputs=acc_task,
                        outputs=[acc_dataset, acc_scheme, acc_infer_type, acc_eval_type, acc_allow_custom], queue=False)
        acc_dataset.change(_on_dataset_change, inputs=[acc_task, acc_dataset],
                           outputs=[acc_scheme, acc_infer_type, acc_eval_type], queue=False)
        acc_scheme.change(_on_scheme_change, inputs=[acc_task, acc_dataset, acc_scheme],
                          outputs=[acc_infer_type, acc_eval_type], queue=False)
        acc_allow_custom.change(_toggle_custom, inputs=[acc_allow_custom, acc_task, acc_dataset, acc_scheme],
                                outputs=[acc_infer_type, acc_eval_type], queue=False)


        # â€”â€” è¿è¡Œ & å¤§æ–‡ä»¶å¤„ç†ï¼ˆä¸å¹²æ‰°æ€§è¯„æµ‹åŒé€»è¾‘ï¼‰â€”â€”
        def _acc_run(task, dataset, scheme_label, infer, eval_, allow_custom,
                     model_name, port, output_dir, key, gpu):
            import time, os, json  # ç¡®ä¿å¯ç”¨
            # å‚æ•°æ ¡éªŒ
            if not validate_combo(task, dataset, scheme_label, infer, eval_, allow_custom):
                return "âŒ è¯„æµ‹å‚æ•°æ— æ•ˆï¼Œè¯·æ£€æŸ¥é€‰æ‹©ã€‚", gr.update(visible=False), gr.update(visible=False), gr.update(
                    visible=False)

            try:
                start_ts = time.time()

                config = {
                    "data": [{"dataset_name": dataset, "type": None}],
                    "model": {"model_name": model_name, "port": int(port), "keys": [key] if key else []},
                    "output": {"output_dir": output_dir},
                    "evaluate": [{"infer_type": infer, "eval_type": eval_}],
                }

                with NamedTemporaryFile(mode="w+", suffix=".yaml", delete=False) as temp_config:
                    yaml.dump(config, temp_config, allow_unicode=True)
                    temp_config_path = temp_config.name

                command = ()

                process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
                                           text=True)

                output_lines = [f"å¯åŠ¨å‡†ç¡®æ€§è¯„æµ‹ï¼štask={task}, dataset={dataset}, infer/eval={infer}/{eval_}"]
                # åˆå§‹å ä½ï¼šåªæ›´æ–°æ—¥å¿—
                yield "\n".join(output_lines), gr.update(), gr.update(), gr.update()

                for line in iter(process.stdout.readline, ''):
                    output_lines.append(line.rstrip("\n"))
                    yield "\n".join(output_lines), gr.update(), gr.update(), gr.update()

                process.wait()

                if process.returncode == 0:
                    json_path = locate_result_json("accuracy", output_dir, model_name, dataset, start_ts)
                    if json_path and os.path.exists(json_path):
                        size = os.path.getsize(json_path)
                        if size <= MAX_JSON_BYTES:
                            with open(json_path, "r", encoding="utf-8") as f:
                                data = json.load(f)
                            output_lines.append(f"âœ… è¯„æµ‹å®Œæˆï¼Œç»“æœæ–‡ä»¶ï¼š{json_path}ï¼ˆ{_fmt_size(size)}ï¼‰")
                            yield "\n".join(output_lines), gr.update(value=data, visible=True), gr.update(
                                visible=False), gr.update(value=json_path, visible=True)
                        else:
                            preview, _ = build_json_preview_from_file(json_path)
                            output_lines.append(f"âœ… è¯„æµ‹å®Œæˆï¼Œç»“æœè¾ƒå¤§ï¼ˆ{_fmt_size(size)}ï¼‰ï¼Œæ˜¾ç¤ºé¢„è§ˆå¹¶æä¾›ä¸‹è½½")
                            yield "\n".join(output_lines), gr.update(visible=False), gr.update(value=preview,
                                                                                               visible=True), gr.update(
                                value=json_path, visible=True)
                    else:
                        output_lines.append("âš ï¸ è¯„æµ‹å®Œæˆï¼Œä½†æœªæ‰¾åˆ°ç»“æœ JSONï¼ˆè¯·æ£€æŸ¥ RESULT_PATTERNS å‘½åä¸å¤§å°å†™ï¼‰ã€‚")
                        yield "\n".join(output_lines), gr.update(visible=False), gr.update(visible=False), gr.update(
                            visible=False)
                else:
                    output_lines.append("âŒ è¯„æµ‹å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
                    yield "\n".join(output_lines), gr.update(visible=False), gr.update(visible=False), gr.update(
                        visible=False)

            except Exception as e:
                return f"âŒ è¿è¡Œå¤±è´¥: {str(e)}", gr.update(visible=False), gr.update(visible=False), gr.update(
                    visible=False)


        acc_button.click(
            _acc_run,
            inputs=[acc_task, acc_dataset, acc_scheme, acc_infer_type, acc_eval_type, acc_allow_custom,
                    acc_model, acc_port, acc_output_dir, acc_key, acc_gpu],
            outputs=[acc_output, acc_result_json, acc_result_preview, acc_result_file]
        )

    # === æŠ—å¹²æ‰°æ€§è¯„æµ‹ ===
    gr.Markdown("## æŠ—å¹²æ‰°æ€§è¯„æµ‹ä»»åŠ¡")

    with gr.Accordion("è¿è¡ŒæŠ—å¹²æ‰°æ€§è¯„æµ‹", open=False):
        # ä»»åŠ¡/æ•°æ®é›†/æ¨èæ­é…ï¼ˆå¤ç”¨å…¨å±€ CONFIG_MATRIXï¼‰
        with gr.Row():
            inter_task = gr.Dropdown(label="ä»»åŠ¡", choices=list(CONFIG_MATRIX.keys()), interactive=True)
            inter_dataset = gr.Dropdown(label="æ•°æ®é›†", choices=[], interactive=True)
            inter_scheme = gr.Dropdown(label="æ¨èæ­é…", choices=[], interactive=True)

        with gr.Row():
            inter_infer_type = gr.Textbox(label="æ¨ç†ç±»å‹", interactive=False)
            inter_eval_type = gr.Textbox(label="è¯„æµ‹ç±»å‹", interactive=False)
        inter_allow_custom = gr.Checkbox(label="å…è®¸è‡ªå®šä¹‰ infer/evalï¼ˆéç‰¹æ®Šä»»åŠ¡ï¼‰", value=False)

        with gr.Row():
            inter_model = gr.Textbox(label="æ¨¡å‹åç§°", value="qwen-vl")
            inter_port = gr.Textbox(label="æ¨¡å‹ç«¯å£", value="3000")

        inter_output_dir = gr.Textbox(
            label="è¾“å‡ºç›®å½•",
            value=""
        )

        with gr.Row():
            # ä»…ä¿ç•™ä¸‹æ‹‰ï¼šå¹²æ‰°ç±»å‹
            INTERFERENCE_CHOICES = ["salt", "gaussian_noise", "motion_blur", "jpeg", "resize"]
            interference_type = gr.Dropdown(
                label="å¹²æ‰°ç±»å‹",
                choices=INTERFERENCE_CHOICES,
                value="salt",
                interactive=True,
            )
            inter_key = gr.Textbox(label="å¯†é’¥ keyï¼ˆå¯é€‰ï¼‰", value="")
            inter_gpu = gr.Textbox(label="GPU ç¼–å·", value="0")

        inter_button = gr.Button("è¿è¡ŒæŠ—å¹²æ‰°æ€§è¯„æµ‹", variant="primary")
        inter_output = gr.Textbox(label="è¾“å‡ºæ—¥å¿—", lines=20, show_copy_button=True)

        # æ–°å¢ä¸‰ä»¶å¥—ï¼ˆé»˜è®¤éšè—ï¼‰
        inter_result_json = gr.JSON(label="è¯„æµ‹ç»“æœï¼ˆâ‰¤512KB è‡ªåŠ¨å±•ç¤ºï¼‰", visible=False)
        inter_result_preview = gr.Code(label="ç»“æœé¢„è§ˆï¼ˆå¤§æ–‡ä»¶æˆªæ–­ï¼‰", language="json", visible=False)
        inter_result_file = gr.File(label="ä¸‹è½½å®Œæ•´ç»“æœ", visible=False)

        # -------- è”åŠ¨ï¼šæ²¿ç”¨å‡†ç¡®æ€§è¯„æµ‹çš„ 3 ä¸ªäº‹ä»¶å¤„ç†å™¨/æ ¡éªŒå™¨ ----------
        inter_task.change(
            _on_task_change, inputs=inter_task,
            outputs=[inter_dataset, inter_scheme, inter_infer_type, inter_eval_type, inter_allow_custom],
            queue=False
        )
        inter_dataset.change(
            _on_dataset_change, inputs=[inter_task, inter_dataset],
            outputs=[inter_scheme, inter_infer_type, inter_eval_type], queue=False
        )
        inter_scheme.change(
            _on_scheme_change, inputs=[inter_task, inter_dataset, inter_scheme],
            outputs=[inter_infer_type, inter_eval_type], queue=False
        )
        inter_allow_custom.change(
            _toggle_custom, inputs=[inter_allow_custom, inter_task, inter_dataset, inter_scheme],
            outputs=[inter_infer_type, inter_eval_type], queue=False
        )


        # -------- è¿è¡Œé€»è¾‘ï¼ˆæµå¼æ—¥å¿— + è‡ªåŠ¨æŠ“ JSONï¼‰ ----------
        def run_interference_eval(task, dataset, scheme_label, infer_type, eval_type, allow_custom,
                                  model_name, port, output_dir, interference, key, gpu):
            import time, os, json  # ç¡®ä¿å¯ç”¨
            # 1) å‚æ•°æ ¡éªŒ
            if not validate_combo(task, dataset, scheme_label, infer_type, eval_type, allow_custom):
                return (
                    "âŒ è¯„æµ‹å‚æ•°æ— æ•ˆï¼Œè¯·æ£€æŸ¥é€‰æ‹©ã€‚",
                    gr.update(visible=False),  # json
                    gr.update(visible=False),  # code
                    gr.update(visible=False),  # file
                )

            try:
                start_ts = time.time()

                config = {
                    "data": [{"dataset_name": dataset, "type": None}],
                    "model": {"model_name": model_name, "port": int(port), "keys": [key] if key else []},
                    "output": {"output_dir": output_dir},
                    "evaluate": [{
                        "infer_type": infer_type,
                        "eval_type": eval_type,
                        "interference": interference,
                        "interference_kwargs": None
                    }]
                }

                with NamedTemporaryFile(mode="w+", suffix=".yaml", delete=False) as temp_config:
                    yaml.dump(config, temp_config, allow_unicode=True)
                    temp_config_path = temp_config.name

                command = ()

                process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
                                           text=True)

                output_lines = [f"å¯åŠ¨æŠ—å¹²æ‰°æ€§è¯„æµ‹ï¼štask={task}, dataset={dataset}, interference={interference}"]
                # âœ… åˆæ¬¡å ä½ï¼šå¿…é¡»è¿”å› 4 ä¸ªå€¼
                yield "\n".join(output_lines), gr.update(), gr.update(), gr.update()

                for line in iter(process.stdout.readline, ''):
                    output_lines.append(line.rstrip("\n"))
                    # âœ… è¿‡ç¨‹é˜¶æ®µä¹Ÿè¦è¿”å› 4 ä¸ªå€¼ï¼ˆå…¶å®ƒä½ç”¨å ä½ç¬¦ä¸å˜æ›´ï¼‰
                    yield "\n".join(output_lines), gr.update(), gr.update(), gr.update()

                process.wait()

                if process.returncode == 0:
                    json_path = locate_result_json(
                        "interference",
                        output_dir=output_dir,
                        model_name=model_name,
                        dataset=dataset,
                        start_ts=start_ts,
                        interference_type=interference,  # æ³¨æ„ï¼šä¼ å€¼ï¼Œä¸æ˜¯ç»„ä»¶
                    )
                    if json_path and os.path.exists(json_path):
                        size = os.path.getsize(json_path)
                        if size <= MAX_JSON_BYTES:
                            with open(json_path, "r", encoding="utf-8") as f:
                                data = json.load(f)
                            output_lines.append(f"âœ… å®Œæˆï¼Œç»“æœæ–‡ä»¶ï¼š{json_path}ï¼ˆ{_fmt_size(size)}ï¼‰")
                            yield (
                                "\n".join(output_lines),
                                gr.update(value=data, visible=True),  # json
                                gr.update(visible=False),  # code
                                gr.update(value=json_path, visible=True),  # file
                            )
                        else:
                            preview, _ = build_json_preview_from_file(json_path)
                            output_lines.append(f"âœ… å®Œæˆï¼Œç»“æœè¾ƒå¤§ï¼ˆ{_fmt_size(size)}ï¼‰ï¼Œæ˜¾ç¤ºé¢„è§ˆå¹¶æä¾›ä¸‹è½½")
                            yield (
                                "\n".join(output_lines),
                                gr.update(visible=False),  # json
                                gr.update(value=preview, visible=True),  # code
                                gr.update(value=json_path, visible=True),  # file
                            )
                    else:
                        output_lines.append("âš ï¸ å®Œæˆï¼Œä½†æœªæ‰¾åˆ°ç»“æœ JSONï¼ˆè¯·æ ¸å¯¹ RESULT_PATTERNS ä¸å¤§å°å†™ï¼‰ã€‚")
                        yield (
                            "\n".join(output_lines),
                            gr.update(visible=False),
                            gr.update(visible=False),
                            gr.update(visible=False),
                        )
                else:
                    output_lines.append("âŒ è¯„æµ‹å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
                    yield (
                        "\n".join(output_lines),
                        gr.update(visible=False),
                        gr.update(visible=False),
                        gr.update(visible=False),
                    )

            except Exception as e:
                # âœ… å¼‚å¸¸æ—¶ä¹Ÿå¿…é¡»è¿”å› 4 ä¸ªå€¼
                return (
                    f"âŒ è¿è¡Œå¤±è´¥: {str(e)}",
                    gr.update(visible=False),
                    gr.update(visible=False),
                    gr.update(visible=False),
                )


        inter_button.click(
            run_interference_eval,
            inputs=[
                inter_task, inter_dataset, inter_scheme, inter_infer_type, inter_eval_type, inter_allow_custom,
                inter_model, inter_port, inter_output_dir, interference_type, inter_key, inter_gpu
            ],
            outputs=[inter_output, inter_result_json, inter_result_preview, inter_result_file]  # â† æ—¥å¿— + ä¸‰ä»¶å¥—
        )

    # === æŠ—æ”»å‡»æ€§è¯„æµ‹ ===
    gr.Markdown("## æŠ—æ”»å‡»æ€§è¯„æµ‹ä»»åŠ¡")

    with gr.Accordion("è¿è¡ŒæŠ—æ”»å‡»æ€§è¯„æµ‹ä»»åŠ¡", open=False):
        with gr.Row():
            atk_dataset = gr.Textbox(label="æ•°æ®é›†åç§°", value="RSICDObject")
            atk_dataset_type = gr.Textbox(label="æ•°æ®é›†ç±»å‹", value="null")
        with gr.Row():
            atk_model = gr.Textbox(label="æ¨¡å‹åç§°", value="qwen-vl")
            atk_port = gr.Textbox(label="æ¨¡å‹ç«¯å£", value="3000")
        atk_output_dir = gr.Textbox(label="è¾“å‡ºç›®å½•",
                                    value="/path/to/output")

        with gr.Row():
            atk_infer_type = gr.Textbox(label="æ¨ç†ç±»å‹", value="object_eval")
            atk_eval_type = gr.Textbox(label="è¯„æµ‹ç±»å‹", value="object_eval")
        with gr.Row():
            atk_attack = gr.Textbox(label="æ”»å‡»æ–¹å¼", value="SSA_CWA_untarget")
            atk_attack_eval_type = gr.Textbox(label="æ”»å‡»è¯„æµ‹æŒ‡æ ‡", value="acc")

        atk_attack_kwargs = gr.Textbox(label="æ”»å‡»å‚æ•° attack_kwargs", value="None")

        with gr.Row():
            atk_http_proxy = gr.Textbox(label="http_proxy", value="")
            atk_https_proxy = gr.Textbox(label="https_proxy", value="")

        atk_key = gr.Textbox(label="å¯†é’¥ key", value="123")
        atk_gpu = gr.Textbox(label="GPU ç¼–å·", value="0")

        atk_button = gr.Button("è¿è¡ŒæŠ—æ”»å‡»æ€§è¯„æµ‹")
        atk_output = gr.Textbox(label="è¯„æµ‹è¾“å‡º", lines=20)


        def run_attack_eval(
                dataset_name, dataset_type,
                model_name, port,
                output_dir,
                infer_type, eval_type,
                attack, attack_eval_type,
                http_proxy, https_proxy,
                attack_kwargs,
                key, gpu):

            # è§£æ attack_kwargsï¼ˆæ”¯æŒ None æˆ– JSONï¼‰
            try:
                atk_kwargs_parsed = None if attack_kwargs.strip() in ["None", "null", ""] else yaml.safe_load(
                    attack_kwargs)
            except Exception:
                atk_kwargs_parsed = None

            config = {
                "data": [{
                    "dataset_name": dataset_name,
                    "type": None if dataset_type == "null" else dataset_type
                }],
                "model": {
                    "model_name": model_name,
                    "port": int(port),
                    "keys": [key] if key else []
                },
                "output": {
                    "output_dir": output_dir
                },
                "evaluate": [{
                    "infer_type": infer_type,
                    "eval_type": eval_type,
                    "keys": [key] if key else [],
                    "proxy": {
                        "http_proxy": http_proxy,
                        "https_proxy": https_proxy
                    },
                    "attack": attack,
                    "attack_kwargs": atk_kwargs_parsed,
                    "attack_eval_type": attack_eval_type
                }]
            }

            try:
                with NamedTemporaryFile(mode="w+", suffix=".yaml", delete=False) as temp_config:
                    yaml.dump(config, temp_config)
                    temp_config_path = temp_config.name

                command = ()

                process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
                                           text=True)
                output_lines = []
                for line in iter(process.stdout.readline, ''):
                    output_lines.append(line.strip())
                    yield "\n".join(output_lines)

                process.wait()
                if process.returncode == 0:
                    yield "âœ… æŠ—æ”»å‡»æ€§è¯„æµ‹å®Œæˆ"
                else:
                    yield "âŒ è¯„æµ‹å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"

            except Exception as e:
                yield f"âŒ è¿è¡Œå¤±è´¥: {str(e)}"


        atk_button.click(
            fn=run_attack_eval,
            inputs=[
                atk_dataset, atk_dataset_type,
                atk_model, atk_port,
                atk_output_dir,
                atk_infer_type, atk_eval_type,
                atk_attack, atk_attack_eval_type,
                atk_http_proxy, atk_https_proxy,
                atk_attack_kwargs,
                atk_key, atk_gpu
            ],
            outputs=atk_output
        )

    # === èŒƒåŒ–æ€§è¯„æµ‹ ===
    gr.Markdown("## æ³›åŒ–æ€§è¯„æµ‹ä»»åŠ¡")

    with gr.Accordion("è¿è¡ŒèŒƒåŒ–æ€§è¯„æµ‹", open=False):
        with gr.Row():
            gen_model = gr.Textbox(label="æ¨¡å‹åç§°", value="qwen-vl")
            gen_port = gr.Textbox(label="æ¨¡å‹ç«¯å£", value="3000")
        gen_output_dir = gr.Textbox(label="è¾“å‡ºç›®å½•",
                                    value="/path/to/output")

        with gr.Row():
            dataset1 = gr.Textbox(label="æ•°æ®é›† 1 åç§°", value="RSICDObject")
            dataset1_type = gr.Textbox(label="æ•°æ®é›† 1 ç±»å‹", value="null")
        with gr.Row():
            dataset2 = gr.Textbox(label="æ•°æ®é›† 2 åç§°", value="FactFailure")
            dataset2_type = gr.Textbox(label="æ•°æ®é›† 2 ç±»å‹", value="null")

        with gr.Row():
            obj_infer_type = gr.Textbox(label="æ•°æ®é›† 1 æ¨ç†ç±»å‹", value="object_eval")
            obj_eval_type = gr.Textbox(label="æ•°æ®é›† 1 è¯„æµ‹ç±»å‹", value="object_eval")
        with gr.Row():
            http_proxy = gr.Textbox(label="http_proxy", value="")
            https_proxy = gr.Textbox(label="https_proxy", value="")

        with gr.Row():
            fact_infer_type = gr.Textbox(label="æ•°æ®é›† 2 æ¨ç†ç±»å‹", value="fact")
            fact_eval_type = gr.Textbox(label="æ•°æ®é›† 2 è¯„æµ‹ç±»å‹", value="fact")

        gen_key = gr.Textbox(label="å¯†é’¥ key", value="123")
        gen_gpu = gr.Textbox(label="GPU ç¼–å·", value="0")

        gen_button = gr.Button("è¿è¡ŒèŒƒåŒ–æ€§è¯„æµ‹")
        gen_output = gr.Textbox(label="è¯„æµ‹è¾“å‡º", lines=20)


        def run_generalization_eval(
                model_name, port, output_dir,
                dataset1, dataset1_type, dataset2, dataset2_type,
                obj_infer_type, obj_eval_type, http_proxy, https_proxy,
                fact_infer_type, fact_eval_type, key, gpu):

            config = {
                "data": [
                    {"dataset_name": dataset1, "type": None if dataset1_type == "null" else dataset1_type},
                    {"dataset_name": dataset2, "type": None if dataset2_type == "null" else dataset2_type}
                ],
                "model": {
                    "model_name": model_name,
                    "port": int(port),
                    "keys": [key] if key else []
                },
                "output": {
                    "output_dir": output_dir
                },
                "evaluate": [
                    {
                        "infer_type": obj_infer_type,
                        "eval_type": obj_eval_type,
                        "keys": [key] if key else [],
                        "proxy": {
                            "http_proxy": http_proxy,
                            "https_proxy": https_proxy
                        }
                    },
                    {
                        "infer_type": fact_infer_type,
                        "eval_type": fact_eval_type
                    }
                ]
            }

            try:
                with NamedTemporaryFile(mode="w+", suffix=".yaml", delete=False) as temp_config:
                    yaml.dump(config, temp_config)
                    temp_config_path = temp_config.name

                command = ()

                process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
                                           text=True)
                output_lines = []
                for line in iter(process.stdout.readline, ''):
                    output_lines.append(line.strip())
                    yield "\n".join(output_lines)

                process.wait()
                if process.returncode == 0:
                    yield "âœ… èŒƒåŒ–æ€§è¯„æµ‹å®Œæˆ"
                else:
                    yield "âŒ è¯„æµ‹å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"

            except Exception as e:
                yield f"âŒ è¿è¡Œå¤±è´¥: {str(e)}"


        gen_button.click(
            fn=run_generalization_eval,
            inputs=[
                gen_model, gen_port, gen_output_dir,
                dataset1, dataset1_type, dataset2, dataset2_type,
                obj_infer_type, obj_eval_type, http_proxy, https_proxy,
                fact_infer_type, fact_eval_type, gen_key, gen_gpu
            ],
            outputs=gen_output
        )

    # === è¿è¡Œæ•ˆç‡è¯„æµ‹ ===
    gr.Markdown("##  è¿è¡Œæ•ˆç‡è¯„æµ‹ä»»åŠ¡")

    with gr.Accordion("è¿è¡Œæ•ˆç‡è¯„æµ‹", open=False):
        with gr.Row():
            eff_dataset = gr.Textbox(label="æ•°æ®é›†åç§°", value="RSICD")
            eff_dataset_type = gr.Textbox(label="æ•°æ®é›†ç±»å‹", value="null")
        with gr.Row():
            eff_model = gr.Textbox(label="æ¨¡å‹åç§°", value="qwen-vl")
            eff_port = gr.Textbox(label="æ¨¡å‹ç«¯å£", value="3000")

        eff_output_dir = gr.Textbox(label="è¾“å‡ºç›®å½•",
                                    value="/path/to/output")

        with gr.Row():
            eff_infer_type = gr.Textbox(label="æ¨ç†ç±»å‹", value="ref")
            eff_eval_type = gr.Textbox(label="è¯„æµ‹ç±»å‹", value="ref")

        eff_key = gr.Textbox(label="å¯†é’¥ key", value="")
        eff_gpu = gr.Textbox(label="GPU ç¼–å·", value="0")

        eff_button = gr.Button("è¿è¡Œæ•ˆç‡è¯„æµ‹")
        eff_output = gr.Textbox(label="è¯„æµ‹è¾“å‡º", lines=20)


        def run_efficiency_eval(dataset_name, dataset_type, model_name, port, output_dir,
                                infer_type, eval_type, key, gpu):

            config = {
                "data": [{
                    "dataset_name": dataset_name,
                    "type": None if dataset_type == "null" else dataset_type
                }],
                "model": {
                    "model_name": model_name,
                    "port": int(port),
                    "keys": [key] if key else []
                },
                "output": {
                    "output_dir": output_dir
                },
                "evaluate": [{
                    "infer_type": infer_type,
                    "eval_type": eval_type
                }]
            }

            try:
                with NamedTemporaryFile(mode="w+", suffix=".yaml", delete=False) as temp_config:
                    yaml.dump(config, temp_config)
                    temp_config_path = temp_config.name

                command = ()

                process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
                                           text=True)
                output_lines = []
                for line in iter(process.stdout.readline, ''):
                    output_lines.append(line.strip())
                    yield "\n".join(output_lines)

                process.wait()
                if process.returncode == 0:
                    yield "âœ… è¿è¡Œæ•ˆç‡è¯„æµ‹å®Œæˆ"
                else:
                    yield "âŒ è¯„æµ‹å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"

            except Exception as e:
                yield f"âŒ è¿è¡Œå¤±è´¥: {str(e)}"


        eff_button.click(
            fn=run_efficiency_eval,
            inputs=[
                eff_dataset, eff_dataset_type, eff_model, eff_port,
                eff_output_dir, eff_infer_type, eff_eval_type, eff_key, eff_gpu
            ],
            outputs=eff_output
        )

    # === é˜²å¾¡è¯„æµ‹ ===
    gr.Markdown("## é˜²å¾¡è¯„æµ‹ä»»åŠ¡")

    with gr.Accordion("è¿è¡Œé˜²å¾¡è¯„æµ‹", open=False):
        with gr.Row():
            def_dataset = gr.Textbox(label="æ•°æ®é›†åç§°", value="RSICDObject")
            def_dataset_type = gr.Textbox(label="æ•°æ®é›†ç±»å‹", value="null")
        with gr.Row():
            def_model = gr.Textbox(label="æ¨¡å‹åç§°", value="qwen2-2b")
            def_port = gr.Textbox(label="æ¨¡å‹ç«¯å£", value="2000")

        def_output_dir = gr.Textbox(label="è¾“å‡ºç›®å½•",
                                    value="/path/to/output")

        with gr.Row():
            def_infer_type = gr.Textbox(label="æ¨ç†ç±»å‹", value="object_eval")
            def_eval_type = gr.Textbox(label="è¯„æµ‹ç±»å‹", value="object_eval")
        with gr.Row():
            def_attack = gr.Textbox(label="æ”»å‡»æ–¹å¼", value="APGD")
            def_attack_eval_type = gr.Textbox(label="æ”»å‡»è¯„æµ‹æŒ‡æ ‡", value="acc")

        def_attack_kwargs = gr.Textbox(label="æ”»å‡»å‚æ•° attack_kwargs", value="None")

        with gr.Row():
            def_http_proxy = gr.Textbox(label="http_proxy", value="")
            def_https_proxy = gr.Textbox(label="https_proxy", value="")

        def_defense = gr.Textbox(label="é˜²å¾¡ç­–ç•¥ defense", value="keg")

        # === åˆ†é¡¹è¾“å…¥ defense_kwargs ===
        def_knowledge_base = gr.Textbox(label="çŸ¥è¯†æ³¨å…¥æ¨¡å‹", value="llava")
        def_dino_port = gr.Textbox(label="dino_port", value="3000")
        def_llava_port = gr.Textbox(label="llava_port", value="4000")
        def_use_label = gr.Checkbox(label="use_label", value=False)

        def_key = gr.Textbox(label="å¯†é’¥ key", value="123")
        def_gpu = gr.Textbox(label="GPU ç¼–å·", value="0")

        def_button = gr.Button("è¿è¡Œé˜²å¾¡è¯„æµ‹")
        def_output = gr.Textbox(label="è¯„æµ‹è¾“å‡º", lines=20)


        def run_defense_eval(
                dataset_name, dataset_type,
                model_name, port, output_dir,
                infer_type, eval_type,
                attack, attack_eval_type,
                http_proxy, https_proxy,
                attack_kwargs,
                defense,
                knowledge_base, dino_port, llava_port, use_label,
                key, gpu):

            try:
                atk_kwargs_parsed = None if attack_kwargs.strip() in ["None", "null", ""] else yaml.safe_load(
                    attack_kwargs)
            except Exception:
                atk_kwargs_parsed = None

            defense_kwargs_parsed = {
                "knowledge_base": knowledge_base,
                "dino_port": int(dino_port),
                "llava_port": int(llava_port),
                "use_label": use_label
            }

            config = {
                "data": [{
                    "dataset_name": dataset_name,
                    "type": None if dataset_type == "null" else dataset_type
                }],
                "model": {
                    "model_name": model_name,
                    "port": int(port),
                    "keys": [key] if key else []
                },
                "output": {
                    "output_dir": output_dir
                },
                "evaluate": [{
                    "infer_type": infer_type,
                    "eval_type": eval_type,
                    "keys": [key] if key else [],
                    "proxy": {
                        "http_proxy": http_proxy,
                        "https_proxy": https_proxy
                    },
                    "attack": attack,
                    "attack_kwargs": atk_kwargs_parsed,
                    "attack_eval_type": attack_eval_type,
                    "defense": defense,
                    "defense_kwargs": defense_kwargs_parsed
                }]
            }

            try:
                with NamedTemporaryFile(mode="w+", suffix=".yaml", delete=False) as temp_config:
                    yaml.dump(config, temp_config)
                    temp_config_path = temp_config.name

                command = ()

                process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
                                           text=True)
                output_lines = []
                for line in iter(process.stdout.readline, ''):
                    output_lines.append(line.strip())
                    yield "\n".join(output_lines)

                process.wait()
                if process.returncode == 0:
                    yield "âœ… é˜²å¾¡è¯„æµ‹å®Œæˆ"
                else:
                    yield "âŒ è¯„æµ‹å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"

            except Exception as e:
                yield f"âŒ è¿è¡Œå¤±è´¥: {str(e)}"


        def_button.click(
            fn=run_defense_eval,
            inputs=[
                def_dataset, def_dataset_type,
                def_model, def_port,
                def_output_dir,
                def_infer_type, def_eval_type,
                def_attack, def_attack_eval_type,
                def_http_proxy, def_https_proxy,
                def_attack_kwargs,
                def_defense,
                def_knowledge_base, def_dino_port, def_llava_port, def_use_label,
                def_key, def_gpu
            ],
            outputs=def_output
        )

# å¯åŠ¨ WebUI
if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7980)



